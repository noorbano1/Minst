# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HwgVZ92Wu9XAWuXT9MYQulzY_NVsiGf3
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

from tensorflow.keras.datasets import mnist
import numpy as np
import pandas as pd

# 1. Load the MNIST dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# 2. Display shapes
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# 3. Class distribution
print("\nClass Distribution in y_train:")
print(pd.Series(y_train).value_counts().sort_index())

# 4. Balanced or Imbalanced
unique, counts = np.unique(y_train, return_counts=True)
if max(counts) - min(counts) < 500:
    print("\nDataset is Balanced")
else:
    print("\nDataset is Imbalanced")

from tensorflow.keras.datasets import mnist
import numpy as np

# Load dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# 1. Normalize pixel values (0–255 → 0–1)
X_train = X_train.astype('float32') / 255
X_test = X_test.astype('float32') / 255

# 2. Reshape images for CNN (28×28×1)
X_train = X_train.reshape(-1, 28, 28, 1)
X_test  = X_test.reshape(-1, 28, 28, 1)

# Show updated shapes
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)

# Show labels
print("y_train labels:", y_train[:20])
print("y_test labels:", y_test[:20])

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

# Build CNN model
model = Sequential()

# 1. Conv2D layer
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)))

# 2. MaxPooling layer
model.add(MaxPooling2D(pool_size=(2,2)))

# 3. Flatten layer
model.add(Flatten())

# 4. Dense layer with ReLU
model.add(Dense(128, activation='relu'))

# 5. Output layer with Softmax (10 classes)
model.add(Dense(10, activation='softmax'))

# Model summary (optional)
model.summary()

model.compile(
    loss='categorical_crossentropy',   # multiclass loss
    optimizer='adam',                  # optimizer
    metrics=['accuracy']               # accuracy metric
)

model.summary()

from tensorflow.keras.utils import to_categorical

# One-hot encode labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=10,
    batch_size=128,
    verbose=1
)

# Evaluate on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print("Test Accuracy:", round(test_accuracy*100, 2), "%")

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Predict labels
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_test, axis=1)

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Display heatmap
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix")
plt.show()

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Training vs Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Training vs Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

train_acc = history.history['accuracy'][-1]
val_acc = history.history['val_accuracy'][-1]
train_loss = history.history['loss'][-1]
val_loss = history.history['val_loss'][-1]

if train_acc > val_acc + 0.05 and val_loss > train_loss:
    print("Model Status: Overfitting")
elif train_acc < 0.90 and val_acc < 0.90:
    print("Model Status: Underfitting")
else:
    print("Model Status: Performing Well")

import matplotlib.pyplot as plt
import numpy as np

# Predict labels
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = np.argmax(y_test, axis=1)

# Display 3x3 grid
plt.figure(figsize=(8,8))
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.imshow(X_test[i].reshape(28,28), cmap='gray')
    plt.title(f"Pred: {y_pred[i]}\nTrue: {y_true[i]}")
    plt.axis('off')
plt.tight_layout()
plt.show()

# Save the trained model
model.save("mnist_cnn.h5")